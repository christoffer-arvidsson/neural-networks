#+TITLE: Restricted boltzmann machine

#+begin_src jupyter-python :exports none
import sys
sys.path.append('../src')

%load_ext autoreload
%autoreload 2
#+end_src

#+RESULTS:
: The autoreload extension is already loaded. To reload it, use:
:   %reload_ext autoreload

* Dataset
#+begin_src jupyter-python
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from model import BoltzmannMachine

dataset = np.array([
    [-1,-1,-1],
    [1,-1,1],
    [-1,1,1],
    [1,1,-1],
])
#+end_src

#+RESULTS:

* Boltzmann machine
#+begin_src jupyter-python
def run_simulation(dataset, k, weight_updates, n_visible, n_hidden,
                   learning_rate, batch_size,
                   generation_iterations, generation_realizations):

    machine= BoltzmannMachine(n_visible, n_hidden)

    # Training
    mus = machine.rng.choice(dataset.shape[0], size=(weight_updates, batch_size), replace=True)
    counts = np.zeros(dataset.shape[0])
    for i in range(weight_updates):
        mu = mus[i]
        machine.run_cd_k(dataset[mu], k=k, learning_rate=learning_rate)

    # Generation
    random_patterns = machine.rng.choice([-1, 1], size=(generation_realizations, n_visible), replace=True)
    patterns = np.zeros((generation_realizations, generation_iterations, n_visible), dtype=int)
    for r in range(generation_realizations):
        patterns[r] = machine.generate(random_patterns[r], iterations=generation_realizations)

    patterns[patterns == -1] = 0
    n_patterns = generation_realizations*generation_iterations
    patterns = patterns.reshape((n_patterns,-1))
    hashes = patterns.dot(1 << np.arange(patterns.shape[-1]-1, -1, -1))
    unique, counts = np.unique(hashes, return_counts=True)

    stored_indices = [0,3,5,6] # Represents the xor patterns
    p_model = counts/(n_patterns)

    return machine, p_model

#+end_src

#+RESULTS:

Train
#+begin_src jupyter-python
k = 100              # monte carlo iterations
weight_updates = 1000
n_visible = 3        # N
n_hidden = [1,2,4,8] # M
learning_rate = 0.1
batch_size = 20
generation_realizations = 1000
generation_iterations = 1000
#+end_src

#+RESULTS:

#+begin_src jupyter-python
machines = []
p_models = []
for i,n in enumerate(n_hidden):
   print(f'Running for n_hidden: {n}', end='\r')
   machine, p_model = run_simulation(dataset, k, weight_updates, n_visible, n,
                                                        learning_rate, batch_size,
                                                        generation_iterations, generation_realizations)
   machines.append(machine)
   p_models.append(p_model)

#+end_src

#+RESULTS:
: Running for n_hidden: 8

#+begin_src jupyter-python :file ../img/kl_div.png
p_data = np.zeros((2**n_visible))
p_data[[0,3,5,6]] = 1/4

kl_divergences = np.zeros(len(p_models))
for i, p_model in enumerate(p_models):
    kl_divergences[i] = np.sum(p_data[p_data!=0] * np.log(p_data[p_data!=0] / p_model[p_data!=0]))

g = sns.lineplot(x=n_hidden, y=kl_divergences, color='black')
g.set_xlabel('$M$ (hidden neurons)')
g.set_ylabel(r'$D_{KL}$')
g.set_title('Kullback-Leibler divergence')
plt.show()
#+end_src

#+RESULTS:
[[file:../img/kl_div.png]]
